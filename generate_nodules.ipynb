{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/BraveheartNL/ISIMI-2021/blob/Lennart_Project/Project/segment_nodule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-jSi12GEWUxh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "\n",
    "import SimpleITK\n",
    "import SimpleITK as sitk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 12)\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from medpy.io import load, save\n",
    "import random\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import scipy.ndimage\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DlZ0dBTfWUxr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\TrainingData\\ISMI Final Project\n"
     ]
    }
   ],
   "source": [
    "config = json.load(open('config.json'))\n",
    "data_folder_path = config[\"data_folder_path\"]\n",
    "print(data_folder_path)\n",
    "ct_folder = f'{data_folder_path}/luna16_nodules/nodule_patches/'\n",
    "mask_folder = f'{data_folder_path}/luna16_nodules/segmentation/'\n",
    "original_xray_folder = f\"{data_folder_path}/original/\"\n",
    "xray_folder = f\"{data_folder_path}/generation_data/preprocessed_images/\"\n",
    "lung_segment_folder = f\"{data_folder_path}/generation_data/lung_segmentations/\"\n",
    "cropped_nodules_folder = f\"{data_folder_path}/valid_nodules/\"\n",
    "results_folder = f\"{data_folder_path}/extended_training_data/images/\"\n",
    "evaluation_data_folder = f\"{data_folder_path}/evaluation_data/\"\n",
    "training_data_folder = f\"{data_folder_path}/preprocessed/\"\n",
    "\n",
    "_, _, xray_names = next(walk(xray_folder))\n",
    "_, _, ct_names = next(walk(ct_folder))\n",
    "_, _, mask_names = next(walk(mask_folder))\n",
    "_, _, cropped_nodule_names = next(walk(cropped_nodules_folder))\n",
    "_, _, lung_segment_names = next(walk(lung_segment_folder))\n",
    "_, _, training_data_names = next(walk(training_data_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0lW8A7KHWUxt"
   },
   "outputs": [],
   "source": [
    "def resample_nodule(ct_data, xray_spacing):\n",
    "    resize_factor = [1,1,1]/xray_spacing\n",
    "    new_real_shape = ct_data.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / ct_data.shape\n",
    "    new_spacing = [1,1,1] / real_resize_factor\n",
    "    resampled_nodule = scipy.ndimage.interpolation.zoom(ct_data, real_resize_factor, mode='nearest')\n",
    "    return resampled_nodule\n",
    "\n",
    "def segment_nodule(ct, mask):\n",
    "    background = np.full(ct.shape, np.min(ct))\n",
    "    segmented_nodule = np.where(mask == 0, background, ct)\n",
    "    return segmented_nodule\n",
    "\n",
    "#Code from the baseline shared by Ecem\n",
    "def project_ct(X_ct, p_lambda = 0.85):\n",
    "    '''\n",
    "    Generate 2D digitally reconstructed radiographs from CT scan. (DRR, fake CXR, simulated CXR)\n",
    "    X_ct: CT scan\n",
    "    p-lambda:  β controls the boosting of X-ray absorption as the tissue density increases.\n",
    "    We have chosen β=0.85 for our experiments after performing a visual comparison with real chest X-rays.\n",
    "    author: Ecem Sogancioglu\n",
    "    '''\n",
    "    X_ct[X_ct > 400] = 400\n",
    "    X_ct[X_ct < -500] = -500\n",
    "    X_ct[X_ct < -1024] = -1024\n",
    "    X_ct += 1024\n",
    "    # 1424 524 698.748232\n",
    "    X_ct = X_ct/1000.0\n",
    "    X_ct *= p_lambda\n",
    "    X_ct[X_ct > 1] = 1\n",
    "    #1.0 0.4454 0.5866707652\n",
    "    X_ct_2d = np.mean(np.exp(X_ct), axis=1)\n",
    "    return X_ct_2d\n",
    "\n",
    "def crop_nodule(ct_2d):\n",
    "    outlines = np.where(ct_2d != np.min(ct_2d))\n",
    "    x_min = np.min(outlines[0])\n",
    "    x_max = np.max(outlines[0])\n",
    "    y_min = np.min(outlines[1])\n",
    "    y_max = np.max(outlines[1])\n",
    "\n",
    "    cropped_patch = ct_2d[x_min:x_max+1, y_min:y_max+1]\n",
    "      \n",
    "    return cropped_patch\n",
    "\n",
    "def normalize_x_ray(cxr):\n",
    "    return ((cxr - cxr.min()) * (1/(cxr.max() - cxr.min()) * 255)).astype('uint8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y74qKClxWUxv"
   },
   "outputs": [],
   "source": [
    "def preprocess_nodule(xray_header, ct, mask):\n",
    "    #Resample the ct and the mask based on Xray spacing\n",
    "\n",
    "    xray_spacing = xray_header.get_voxel_spacing()\n",
    "    resampled_ct = resample_nodule(ct, np.array([xray_spacing[0],xray_spacing[1],xray_spacing[0]]))\n",
    "    resampled_mask = resample_nodule(mask, np.array([xray_spacing[0],xray_spacing[1],xray_spacing[0]]))\n",
    "\n",
    "    #Segment the nodule using the mask\n",
    "    segmented_ct = segment_nodule(resampled_ct, resampled_mask)\n",
    "    \n",
    "    #Project the segmented CT data from 3d to 2d\n",
    "    ct_2d = project_ct(segmented_ct)\n",
    "\n",
    "    return ct_2d\n",
    "\n",
    "def normalize_nodule(xray_arr, cropped_nodule, location):\n",
    "    x = location[0]\n",
    "    y = location[1]\n",
    "    ct_2d = cropped_nodule\n",
    "\n",
    "    x_min, x_max = ct_2d.shape[0]//2, ct_2d.shape[0]//2\n",
    "    y_min, y_max = ct_2d.shape[1]//2, ct_2d.shape[1]//2\n",
    "\n",
    "    if ct_2d.shape[0] % 2 != 0:\n",
    "        x_max+=1\n",
    "    if ct_2d.shape[1] % 2 != 0:\n",
    "        y_max+=1\n",
    "\n",
    "    #normalize projected ct\n",
    "    n_max = np.max(xray_arr[ x-x_min:x+x_max, y-y_min:y+y_max ])\n",
    "    n_min = np.min(xray_arr[ x-x_min:x+x_max, y-y_min:y+y_max ])\n",
    "    ct_2d = ((ct_2d-ct_2d.min())*(1/(ct_2d.max() - ct_2d.min()) * (n_max - n_min))+n_min).astype('uint8')\n",
    "    return ct_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "v8Y88uhFWUx1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef litjens_mean_superimpose(location: tuple, nodule: np.array, xray: np.array) -> np.array:\\n    x = location[0]\\n    y = location[1]\\n    x_min, x_max = nodule.shape[0]//2, nodule.shape[0]//2\\n    y_min, y_max = nodule.shape[1]//2, nodule.shape[1]//2\\n\\n    if nodule.shape[0] % 2 != 0:\\n        x_max+=1\\n    if nodule.shape[1] % 2 != 0:\\n        y_max+=1\\n    xray_patch = xray[x-x_min:x+x_max,y-y_min:y+y_max]\\n    valued_indices = nodule != (1.0 * nodule.min())\\n    nodule[valued_indices] = np.mean(np.array([xray_patch[valued_indices],nodule[valued_indices]]), axis=0)\\n    nodule[~valued_indices] = xray_patch[~valued_indices]\\n\\n    xray[x-x_min:x+x_max,y-y_min:y+y_max] = nodule\\n\\n    C = xray_patch.max() - xray_patch.min()\\n    D = np.sqrt(nodule.shape[0]**2 + nodule.shape[1]**2)\\n    for i in range(nodule.shape[0]):\\n        for j in range(nodule.shape[1]):\\n            r = np.sqrt((nodule.shape[0]//2-i)**2 + (nodule.shape[1]//2-j)**2)\\n            c = C*( 4*r**4/D**4 - 4.2*r**2/D**2 + 1)\\n            xray[x - nodule.shape[0]//2+i, y-nodule.shape[1]//2+j]+=nodule[i,j]*c\\n    return xray\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Superimposition section\n",
    "#spot on the CXR to locate the nodule\n",
    "def normalization(x):\n",
    "    x = x.copy()\n",
    "    x = (x - x.min()) / (x.max() - x.min())\n",
    "    return x\n",
    "\n",
    "\n",
    "def mean_superimpose(location: tuple, nodule: np.array, xray: np.array) -> np.array:\n",
    "    x = location[0]\n",
    "    y = location[1]\n",
    "    x_min, x_max = nodule.shape[0]//2, nodule.shape[0]//2\n",
    "    y_min, y_max = nodule.shape[1]//2, nodule.shape[1]//2\n",
    "\n",
    "    if nodule.shape[0] % 2 != 0:\n",
    "        x_max+=1\n",
    "    if nodule.shape[1] % 2 != 0:\n",
    "        y_max+=1\n",
    "    xray_patch = xray[x-x_min:x+x_max,y-y_min:y+y_max]\n",
    "    valued_indices = (nodule > 1.1 * nodule.min())\n",
    "    # blend cxr patch and nodule patch\n",
    "    nodule[valued_indices] = np.mean(np.array([xray_patch[valued_indices],nodule[valued_indices]]), axis=0)\n",
    "    nodule[~valued_indices] = xray_patch[~valued_indices]\n",
    "\n",
    "    xray[x-x_min:x+x_max,y-y_min:y+y_max] = nodule\n",
    "    return xray\n",
    "\n",
    "'''\n",
    "def litjens_mean_superimpose(location: tuple, nodule: np.array, xray: np.array) -> np.array:\n",
    "    x = location[0]\n",
    "    y = location[1]\n",
    "    x_min, x_max = nodule.shape[0]//2, nodule.shape[0]//2\n",
    "    y_min, y_max = nodule.shape[1]//2, nodule.shape[1]//2\n",
    "\n",
    "    if nodule.shape[0] % 2 != 0:\n",
    "        x_max+=1\n",
    "    if nodule.shape[1] % 2 != 0:\n",
    "        y_max+=1\n",
    "    xray_patch = xray[x-x_min:x+x_max,y-y_min:y+y_max]\n",
    "    valued_indices = nodule != (1.0 * nodule.min())\n",
    "    nodule[valued_indices] = np.mean(np.array([xray_patch[valued_indices],nodule[valued_indices]]), axis=0)\n",
    "    nodule[~valued_indices] = xray_patch[~valued_indices]\n",
    "\n",
    "    xray[x-x_min:x+x_max,y-y_min:y+y_max] = nodule\n",
    "\n",
    "    C = xray_patch.max() - xray_patch.min()\n",
    "    D = np.sqrt(nodule.shape[0]**2 + nodule.shape[1]**2)\n",
    "    for i in range(nodule.shape[0]):\n",
    "        for j in range(nodule.shape[1]):\n",
    "            r = np.sqrt((nodule.shape[0]//2-i)**2 + (nodule.shape[1]//2-j)**2)\n",
    "            c = C*( 4*r**4/D**4 - 4.2*r**2/D**2 + 1)\n",
    "            xray[x - nodule.shape[0]//2+i, y-nodule.shape[1]//2+j]+=nodule[i,j]*c\n",
    "    return xray\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_metadata = {\n",
    "        'height':    [],\n",
    "        'original_name': [],\n",
    "        'width':     [],\n",
    "        'x'    :     [],\n",
    "        'y'    :     [],\n",
    "        'dataset':   [],\n",
    "        'img_name':  []\n",
    "        }\n",
    "\n",
    "for i in range(1134):\n",
    "    #pick random xray and nodule\n",
    "    random_xray_index = np.random.randint(0, len(xray_names))\n",
    "    random_cropped_nodule_index = np.random.randint(0, len(cropped_nodule_names))\n",
    "    \n",
    "    # normalize cxr\n",
    "    xray, xray_header = load(os.path.join(xray_folder, xray_names[random_xray_index]))\n",
    "    xray_mask, xray_mask_header = load(os.path.join(lung_segment_folder, lung_segment_names[random_xray_index]))\n",
    "    n_xray = normalize_x_ray(xray)\n",
    "    \n",
    "    #choose location to place nodule\n",
    "    valid_y, valid_x = np.where(xray_mask)\n",
    "    location = np.random.randint(len(valid_x))\n",
    "    x, y = [valid_x[location], valid_y[location]]\n",
    "\n",
    "    # use valid_nodules.\n",
    "    random_cropped_nodule_file = cropped_nodule_names[random_cropped_nodule_index]\n",
    "    random_cropped_nodule = load(os.path.join(cropped_nodules_folder, random_cropped_nodule_file))[0]\n",
    "    \n",
    "    normalized_nodule = normalize_nodule(xray_arr=n_xray,\n",
    "                                     cropped_nodule=random_cropped_nodule,\n",
    "                                     location=(y, x))\n",
    "\n",
    "    result = mean_superimpose((y, x), normalized_nodule, n_xray)\n",
    "\n",
    "    save(result, f\"{results_folder}{1135+i}.png\")\n",
    "    \n",
    "    #update metadata\n",
    "    gen_metadata['height'].append(random_cropped_nodule.shape[0])\n",
    "    gen_metadata['original_name'].append('-')\n",
    "    gen_metadata['width'].append(random_cropped_nodule.shape[1])\n",
    "    gen_metadata['x'].append(x)\n",
    "    gen_metadata['y'].append(y)\n",
    "    gen_metadata['dataset'].append('-')\n",
    "    gen_metadata['img_name'].append(f\"{1135+i}.png\")\n",
    "    \n",
    "    if i%50 == 0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gen_metadata_df = DataFrame(gen_metadata)\n",
    "gen_metadata_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2106 entries, 0 to 2105\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   height         2106 non-null   int64 \n",
      " 1   original_name  2106 non-null   object\n",
      " 2   width          2106 non-null   int64 \n",
      " 3   x              2106 non-null   int64 \n",
      " 4   y              2106 non-null   int64 \n",
      " 5   dataset        2106 non-null   object\n",
      " 6   img_name       2106 non-null   object\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 115.3+ KB\n"
     ]
    }
   ],
   "source": [
    "og_metadata_df = pd.read_csv('./Data/training_data/metadata.csv')\n",
    "og_metadata_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3240 entries, 0 to 1133\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   height         3240 non-null   int64 \n",
      " 1   original_name  3240 non-null   object\n",
      " 2   width          3240 non-null   int64 \n",
      " 3   x              3240 non-null   int64 \n",
      " 4   y              3240 non-null   int64 \n",
      " 5   dataset        3240 non-null   object\n",
      " 6   img_name       3240 non-null   object\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 202.5+ KB\n"
     ]
    }
   ],
   "source": [
    "complete_metadata_df = pd.concat([og_metadata_df, gen_metadata_df])\n",
    "complete_metadata_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_metadata_df.to_csv(f'{data_folder_path}/extended_training_data/metadata.csv', index=False, mode='w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data_set(names, all_metadata, output_file, num_files=100):\n",
    "    \"\"\"\n",
    "    generate dataset and\n",
    "\n",
    "    :param names: all names of files (.mha files)\n",
    "    :param all_metadata: metadata of names files\n",
    "    :param output_file: outputs normalized images of num_files random records from names, and metadata file\n",
    "    :param num_files: num files saved to output_file and represented in meta datafile\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dataset_metadata = pd.DataFrame(columns=all_metadata.columns)\n",
    "    dataset_names = names[np.random.randint(0, len(names), size=num_files)]\n",
    "    for name in dataset_names:\n",
    "        img = load(os.path.join(training_data_folder, name))[0]\n",
    "        img = normalize_x_ray(img)\n",
    "        save(img, os.path.join(evaluation_data_folder, name.split(\".\")[0]+\".png\"))\n",
    "        if name in list(all_metadata['img_name']):\n",
    "            records = all_metadata[all_metadata['img_name'] == name]\n",
    "            records['img_name'] = records['img_name'].iloc[0].split('.')[0]+\".png\"\n",
    "            dataset_metadata = dataset_metadata.append(records)\n",
    "\n",
    "    dataset_metadata.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-0e5782eacf9b>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  records['img_name'] = records['img_name'].iloc[0].split('.')[0]+\".png\"\n"
     ]
    }
   ],
   "source": [
    "generate_data_set(np.array(training_data_names),\n",
    "                  pd.read_csv(f\"{data_folder_path}/metadata_preprocessed.csv\"),\n",
    "                  os.path.join(evaluation_data_folder, \"eval_metadata.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "segment_nodule.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "477b8bb12dd12a8c9bb00e1c0589c9baac9f9a6594648eff851f61f960fda1ec"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
